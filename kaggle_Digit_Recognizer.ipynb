{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/Users/ting/Desktop/kaggle_Digit_Recognizer/')\n",
    "\n",
    "#read data\n",
    "x = pd.read_csv(\"train.csv\")\n",
    "x \n",
    "x_train = np.array(x.loc[:, 'pixel0' : 'pixel783'])\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_train.shape\n",
    "\n",
    "#改變y_train的資料型態\n",
    "#y_train = np.array(x.loc[:, 'label'])\n",
    "y_train = pd.DataFrame(x.loc[:, 'label'])\n",
    "y_1 = []\n",
    "for i in range(0, 42000):\n",
    "    lab_nu = y_train.loc[:, 'label'][i]\n",
    "    y = np.zeros(10)\n",
    "    y[lab_nu] = 1\n",
    "    y = [y]\n",
    "    y_1.append(y)\n",
    "\n",
    "y_1 = np.array(y_1)\n",
    "\n",
    "#reshape\n",
    "y_2 = []\n",
    "for i in range(0, 42000):\n",
    "    y_3 = y_1[i][0]\n",
    "    y_2.append(y_3)\n",
    "\n",
    "y_2 = np.array(y_2)\n",
    "y_2.shape\n",
    "y_train_1 = y_2\n",
    "y_train = y_train_1.astype(np.float32)\n",
    "\n",
    "x_test = pd.read_csv(\"test.csv\").astype(np.float32)\n",
    "x_test = np.array(x_test.loc[:, 'pixel0' : 'pixel783'])\n",
    "x_test = x_test.astype(np.float32)\n",
    "x_test\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.1\n",
      "100 0.86\n",
      "200 0.94\n",
      "300 0.92\n",
      "400 0.88\n",
      "500 0.98\n",
      "600 0.96\n",
      "700 0.98\n",
      "800 0.86\n",
      "900 0.94\n",
      "1000 0.96\n",
      "1100 0.96\n",
      "1200 1.0\n",
      "1300 0.98\n",
      "1400 0.96\n",
      "1500 0.98\n",
      "1600 0.96\n",
      "1700 0.94\n",
      "1800 0.94\n",
      "1900 0.94\n",
      "2000 0.94\n",
      "2100 0.96\n",
      "2200 0.98\n",
      "2300 0.98\n",
      "2400 1.0\n",
      "2500 1.0\n",
      "2600 0.98\n",
      "2700 1.0\n",
      "2800 1.0\n",
      "2900 0.96\n",
      "3000 0.94\n",
      "3100 0.96\n"
     ]
    }
   ],
   "source": [
    "#set parameters\n",
    "n_features = x_train.shape[1]\n",
    "n_labels = y_train.shape[1]\n",
    "\n",
    "#set input/output\n",
    "sess = tf.InteractiveSession()\n",
    "with tf.name_scope('Input'):\n",
    "    x = tf.placeholder(tf.float32, shape = [None, n_features])\n",
    "with tf.name_scope('Labels'):\n",
    "    y = tf.placeholder(tf.float32, shape = [None, n_labels])\n",
    "\n",
    "#def varible\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape = shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#def conv and maxpool\n",
    "def conv2d(x, w):\n",
    "    return tf.nn.conv2d(x, w, strides = [1,1,1,1], padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "\n",
    "#set layer\n",
    "#first\n",
    "with tf.name_scope('FirstConvolutionLayer'):\n",
    "    wei_conv_1 = weight_variable([5,5,1,32])\n",
    "    bia_conv_1 = bias_variable([32])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "#tf.reshape(x, [-1???,28,28,1])\n",
    "    conv_1 = tf.nn.relu(conv2d(x_image, wei_conv_1) + bia_conv_1)\n",
    "    max_pool_1 = max_pool_2x2(conv_1)\n",
    "\n",
    "#sec\n",
    "with tf.name_scope('SecConvLayer'):\n",
    "    wei_conv_2 = weight_variable([5,5,32,64])\n",
    "    bia_conv_2 = bias_variable([64])\n",
    "    conv_2 = tf.nn.relu(conv2d(max_pool_1, wei_conv_2) + bia_conv_2)\n",
    "    max_pool_2 = max_pool_2x2(conv_2)\n",
    "    \n",
    "#full connection\n",
    "with tf.name_scope('FullConnectionLayer'):\n",
    "    wei_conv_3 = weight_variable([7 * 7 *64, 1024])\n",
    "    bia_conv_3 = bias_variable([1024])\n",
    "    max_pool_2_flat = tf.reshape(max_pool_2, [-1, 7 * 7 * 64])\n",
    "    fcon_1 = tf.nn.relu(tf.matmul(max_pool_2_flat, wei_conv_3) + bia_conv_3)\n",
    "\n",
    "#dropout fun\n",
    "with tf.name_scope('DropFun'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    fcon_1_dop_fun = tf.nn.dropout(fcon_1, keep_prob = keep_prob)\n",
    "\n",
    "#outlayer\n",
    "with tf.name_scope('OutLayer'):\n",
    "    wei_out = weight_variable([1024, 10])\n",
    "    bia_out = bias_variable([10])\n",
    "    y_outlay = tf.matmul(fcon_1_dop_fun, wei_out) + bia_out\n",
    "\n",
    "#train and opt\n",
    "with tf.name_scope('CossEntropy'):\n",
    "    cross_entro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y, logits = y_outlay))\n",
    "#labels = y, logits = y_outlay\n",
    "    tf.summary.scalar(\"CossEntropy\", cross_entro)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entro)\n",
    "#tf.train.AdamOptimizer(1e-4???).minimize(cross_entro)\n",
    "correct_pre = tf.equal(tf.argmax(y_outlay, 1), tf.argmax(y, 1))\n",
    "with tf.name_scope('Accurancy'):\n",
    "    acc = tf.reduce_mean(tf.cast(correct_pre, tf.float32))\n",
    "    tf.summary.scalar(\"Accurancy\", acc)\n",
    "\n",
    "#init\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "#visualization\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('TensorBoard/', graph = tf.get_default_graph())\n",
    "\n",
    "#opt  \n",
    "tra = []\n",
    "for i in range(15000):\n",
    "    ran = np.random.randint(1, 42000, 50)\n",
    "    x_tra = x_train[ran]\n",
    "    y_tra = y_train[ran]\n",
    "#    batch = mnist.train.next_batch(50)\n",
    "#batch[1], batch[0] == batch_xs, batch_ys\n",
    "    if i%100 == 0:\n",
    "        train_acc = acc.eval(feed_dict = {x: x_tra, y: y_tra, keep_prob: 1.0})\n",
    "        print(i, train_acc)\n",
    "#        summary = sess.run(merged, feed_dict = {x: x_tra, y: y_tra, keep_prob: 1.0})\n",
    "# x feed不進去？\n",
    "#        writer.add_summary(summary, i)\n",
    "#write.add_summary(summary, i???)\n",
    "#        writer.flush()\n",
    "    train_step.run(feed_dict = {x: x_tra, y: y_tra, keep_prob: 0.5})\n",
    "#train_step.run again???\n",
    "\n",
    "res_1 = y_outlay.eval(feed_dict = {x: x_train, keep_prob: 1.0})\n",
    "res_1 = pd.DataFrame(res_1)\n",
    "#test\n",
    "#print(acc.eval(feed_dict = {x: x_test, y: y_test, keep_prob: 1.0}))\n",
    "#print(y_outlay.eval(feed_dict = {x: x_test, keep_prob: 1.0}))\n",
    "#res = y_outlay.eval(feed_dict = {x: x_test, keep_prob: 1.0})\n",
    "res = y_outlay.eval(feed_dict = {x: x_test, keep_prob: 1.0})\n",
    "#type(res)\n",
    "\n",
    "#res = tf.argmax(res, 1)\n",
    "#res = np.nonzero(res)[1]\n",
    "res = pd.DataFrame(res)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "res_1.to_csv(\"res_1.csv\")\n",
    "res.to_csv(\"res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
